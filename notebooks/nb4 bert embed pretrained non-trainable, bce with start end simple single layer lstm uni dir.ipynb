{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rushikej/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/rushikej/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/rushikej/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/rushikej/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/rushikej/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/rushikej/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "\n",
    "import spacy\n",
    "\n",
    "import time\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def foo(row):\n",
    "#     z = ['none', 'start']\n",
    "    \n",
    "#     temp = row['start_idx']\n",
    "#     ans = np.zeros(len(row['text'].split()))\n",
    "#     ans[temp] = 1\n",
    "#     ans = np.array(ans, dtype=np.int32)\n",
    "#     ans = ' '.join([str(z[ans_]) for ans_ in ans])\n",
    "#     return ans\n",
    "\n",
    "# def foo2(row):\n",
    "#     try:\n",
    "#         temp = row['start_idx']\n",
    "#         temp += len(row['selected_text'].split())\n",
    "#         temp -= 1\n",
    "#         end_idx = temp\n",
    "#         ans = np.zeros(len(row['text'].split()))\n",
    "#         ans[temp] = 1\n",
    "#     except:\n",
    "#         print(row)\n",
    "#         import sys; sys.exit(0)\n",
    "#     ans = np.array(ans, dtype=np.int32)\n",
    "#     z = ['none', 'end']\n",
    "#     ans = ' '.join([str(z[ans_]) for ans_ in ans])\n",
    "#     return ans\n",
    "\n",
    "# def foo3(row):\n",
    "#     temp = row['text'].find(row['selected_text'])\n",
    "#     if temp>0: \n",
    "#         if row['text'][temp-1]!=' ': \n",
    "#             temp = row['text'].rfind(' ',0,temp)\n",
    "#             if temp==-1: \n",
    "#                 temp=0\n",
    "#     temp = len(row['text'][:temp].split())\n",
    "#     return temp\n",
    "\n",
    "# def foo4(row):\n",
    "#     row_final = []\n",
    "#     ele = 'none'\n",
    "# #     print(row['start'])\n",
    "#     for rows, rowe in zip(row['start'].split(), row['end'].split()):\n",
    "# #         print(rows)\n",
    "#         if rows == 'start': ele = 'selection'\n",
    "#         row_final.append(ele)\n",
    "#         if rowe == 'end': ele = 'none'\n",
    "#     row_final = ' '.join(row_final)\n",
    "#     return row_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tqdm.pandas()\n",
    "# df = pd.read_csv('../tweet-sentiment-extraction/train.csv')\n",
    "\n",
    "# if len(df[df['textID']=='fdb77c3752'])!=0:\n",
    "#     df = df.drop([314])\n",
    "\n",
    "# df['start_idx'] = df.progress_apply(foo3, axis=1)\n",
    "# df['start'] = df.progress_apply(foo, axis=1)\n",
    "# df['end'] = df.progress_apply(foo2, axis=1)\n",
    "# df['selection'] = df.progress_apply(foo4, axis=1)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df, test_df = train_test_split(df, test_size=0.1)\n",
    "# train_df, val_df = train_test_split(train_df, test_size=0.1)\n",
    "\n",
    "# train_df.to_csv('df_changed_train.csv')\n",
    "# val_df.to_csv('df_changed_val.csv')\n",
    "# test_df.to_csv('df_changed_test.csv')\n",
    "\n",
    "train_path = 'df_changed_train.csv'\n",
    "test_path = 'df_changed_test.csv'\n",
    "val_path = 'df_changed_val.csv'\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "val_df = pd.read_csv(val_path)\n",
    "test_df = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#', 't', '##far', '##p', '*', 'takes', 'a', 'moment', 'to', 'translate', ',', 'then', 'nods', '*', 'you', '`', 're', 'quite', 'welcome', '.', 'also', ',', 'dear', ',', 'it', '`', 's', 'probably', 'best', 'if', 'you', 'stay', 'here', 'again', '-']\n",
      "\n",
      "['just', 'back', 'from', 'graduation', '.', 'two', 'more', 'doctors', 'in', 'the', 'family', 'now']\n",
      "\n",
      "['if', 'i', 'make', 'some', 'madeleine', '##s', ',', 'i', 'need', 'to', 'have', 'a', 'ba', '##ke', 'sale', 'or', 'something', '.', 'god', '.', 'boredom', 'needs', 'to', '=', 'something', 'other', 'than', 'baking']\n",
      "\n",
      "['come', 'on', 'vancouver', '.', 'throwing', 'stuff', 'onto', 'the', 'ice', '?', 'i', 'thought', 'you', 'canucks', 'were', 'supposed', 'to', 'be', 'all', 'polite', 'and', 'stuff', '?']\n",
      "\n",
      "['aw', '##w', 'poor', 'cai', '##ty', ':', 'l', 'add', 'people', 'n', 'they', 'will', 'add', 'you']\n",
      "\n",
      "['online', '!']\n",
      "\n",
      "['jenna', '##h', 'can', 'u', 'just', 'tell', 'jay', 'i', 'said', 'good', 'night', 'pl', '##z', '?', 'im', 'asking', 'nicely', '!']\n",
      "\n",
      "['2nd', 'breakfast', '!', '?', 'i', 'want', 'more', 'food', '=', '/', 'lo', '##l', '.', 't', '##wee', '##t', 'me', 'what', 'breakfast', 'you', '`', 're', 'having', 'lo', '##oo', '##oo', '##old', '##ing', '`']\n",
      "\n",
      "['http', ':', '/', '/', 't', '##wi', '##tp', '##ic', '.', 'com', '/', '2', '##sw', '##4', '##v', '-', 'i', 'love', 'both', 'your', 'hairs', '##ss']\n",
      "\n",
      "['just', 'like', 'the', 'old', 'days', 'drink', '##in', 'at', 'the', 'old', 'spot', '.']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for l in (list(map(lambda t: tokenizer.tokenize(t), train_df['text'][:10]))):\n",
    "    print(l)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = list(map(lambda t: tokenizer.tokenize(t), train_df['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_field = data.Field(sequential=True)\n",
    "# text_id_field = data.Field(sequential=False)\n",
    "\n",
    "labels_field = data.Field(sequential=False)\n",
    "# start_field = data.Field(unk_token=None, pad_token='none')\n",
    "# end_field = data.Field(unk_token=None, pad_token='none')\n",
    "\n",
    "selection_field = data.Field(unk_token=None, pad_token='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields={    # 'textID': ('textID', text_id_field),\n",
    "            'text': ('text', text_field),\n",
    "            \n",
    "            # 'selected_text': ('selected_text', selected_text_field),\n",
    "            'sentiment': ('labels', labels_field), \n",
    "            # 'start': ('start', start_field), \n",
    "            # 'end': ('end', end_field)\n",
    "            \n",
    "            'selection': ('selection', selection_field)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, test_data = data.TabularDataset.splits(\n",
    "    path='', \n",
    "    train=train_path,\n",
    "    validation=val_path, \n",
    "    test=test_path, \n",
    "    format='csv',\n",
    "    fields=fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 22258\n",
      "Number of validation examples: 2474\n",
      "Number of testing examples: 2748\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training examples: {len(train_data)}\")\n",
    "print(f\"Number of validation examples: {len(val_data)}\")\n",
    "print(f\"Number of testing examples: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_field.build_vocab(train_data, \n",
    "                 min_freq = 5,\n",
    "                 vectors = \"glove.6B.100d\",\n",
    "                 unk_init = torch.Tensor.normal_)\n",
    "labels_field.build_vocab(train_data)\n",
    "# start_field.build_vocab(train_data)\n",
    "# end_field.build_vocab(train_data)\n",
    "selection_field.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_field.vocab.freqs\n",
    "assert(selection_field.vocab.stoi['none']==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "device = torch.device('cuda:2')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, val_data, test_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    sort_key = lambda x: x.text,\n",
    "    sort_within_batch = False,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentExtractor(nn.Module):\n",
    "    def __init__(self,\n",
    "                input_dim,\n",
    "                outputs_dim,\n",
    "                embedding_dim,\n",
    "                hidden_dim,\n",
    "                pad_idx,\n",
    "                dropout_rate,\n",
    "                num_layers,\n",
    "                bidirectional\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim, padding_idx=pad_idx)\n",
    "        \n",
    "        if num_layers == 1:\n",
    "            dropout_rate=0\n",
    "        \n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, \n",
    "                            num_layers=num_layers, bidirectional=bidirectional, dropout=dropout_rate)\n",
    "        \n",
    "        # self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        if bidirectional:\n",
    "            self.fc = nn.Linear(hidden_dim*2, outputs_dim)\n",
    "        else:\n",
    "            self.fc = nn.Linear(hidden_dim, outputs_dim)\n",
    "    \n",
    "    def forward(self, text, sentiment):\n",
    "        # embeddings = self.dropout(self.embedding(text))\n",
    "        embeddings = self.embedding(text)\n",
    "        output, (hidden, cell) = self.lstm(embeddings)\n",
    "        \n",
    "        \n",
    "        print(output.shape)\n",
    "        # return self.fc(self.dropout(output))\n",
    "        return self.fc(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(text_field.vocab)\n",
    "outputs_dim = 1\n",
    "hidden_dim = 64\n",
    "num_layers = 1\n",
    "bidirectional = False\n",
    "dropout_rate = 0.25\n",
    "pad_idx = text_field.vocab.stoi[text_field.pad_token]\n",
    "embedding_dim = 100\n",
    "\n",
    "model = SentimentExtractor(input_dim=input_dim,\n",
    "                 outputs_dim=outputs_dim,\n",
    "                 hidden_dim=hidden_dim,\n",
    "                 num_layers=num_layers,\n",
    "                 bidirectional=bidirectional,\n",
    "                 dropout_rate=dropout_rate,\n",
    "                 embedding_dim=embedding_dim,\n",
    "                 pad_idx=pad_idx)\n",
    "\n",
    "# tag_pad_idx = UD_TAGS.vocab.stoi[UD_TAGS.pad_token]\n",
    "# criterion = nn.CrossEntropyLoss(ignore_index=tag_pad_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.normal_(param.data, mean = 0, std = 0.1)\n",
    "        \n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        \n",
    "model.apply(init_weights);\n",
    "\n",
    "# print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "pretrained_embeddings = text_field.vocab.vectors\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings);\n",
    "\n",
    "model.embedding.weight.data[1] = torch.zeros(embedding_dim)\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([26, 32])\n",
      "tensor([  85,   70,  972,   44,    0,  556,    6,    3,  389, 1823,    3, 1764,\n",
      "         209, 1963,    8,    0,  144,  241,   26,    0,   10,  152,    8,    0,\n",
      "          71, 3063, 4047,    0,    0,   93, 1204,  915], device='cuda:2')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for batch in train_iterator:\n",
    "        text = batch.text\n",
    "        # preds = model(text)\n",
    "        print(text.shape)\n",
    "        print(text[0])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def custom_categorical_accuracy(y_pred, y_true, tag_pad_idx):\n",
    "#     y_pred = y_pred.argmax(dim=1, keepdim=True)\n",
    "#     non_pad_element_idxs = (y_true!=tag_pad_idx).nonzero()\n",
    "#     correct = y_pred[non_pad_element_idxs].squeeze(1).eq(y_true[non_pad_element_idxs])\n",
    "#     return correct.sum() / torch.FloatTensor([y_true[non_pad_element_idxs].shape[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def lovasz_grad(gt_sorted):\n",
    "    \"\"\"\n",
    "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
    "    See Alg. 1 in paper\n",
    "    \"\"\"\n",
    "    p = len(gt_sorted)\n",
    "    gts = gt_sorted.sum()\n",
    "    intersection = gts - gt_sorted.float().cumsum(0)\n",
    "    union = gts + (1 - gt_sorted).float().cumsum(0)\n",
    "    jaccard = 1. - intersection / union\n",
    "    if p > 1: # cover 1-pixel case\n",
    "        jaccard[1:p] = jaccard[1:p] - jaccard[0:-1]\n",
    "    return jaccard\n",
    "\n",
    "def lovasz_hinge_flat(logits, labels):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
    "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
    "      ignore: label to ignore\n",
    "    \"\"\"\n",
    "    if len(labels) == 0:\n",
    "        # only void pixels, the gradients should be 0\n",
    "        return logits.sum() * 0.\n",
    "    signs = 2. * labels.float() - 1.\n",
    "    errors = (1. - logits * Variable(signs))\n",
    "    errors_sorted, perm = torch.sort(errors, dim=0, descending=True)\n",
    "    perm = perm.data\n",
    "    gt_sorted = labels[perm]\n",
    "    grad = lovasz_grad(gt_sorted)\n",
    "    loss = torch.dot(F.relu(errors_sorted), Variable(grad))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, iterator, loss_func, optimizer):    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    model.to(device)\n",
    "    with torch.enable_grad():\n",
    "#     with torch.no_grad():\n",
    "        model.train()\n",
    "#         model.eval()\n",
    "        for batch in iterator:\n",
    "            text = batch.text\n",
    "#             print('Text shape: ', text.shape)\n",
    "\n",
    "            preds = model(batch.text)\n",
    "#             print(preds.shape)\n",
    "#             print(preds)\n",
    "#             print('\\n\\n\\n\\n')\n",
    "            preds = preds.view(-1)\n",
    "            true = batch.selection\n",
    "#             print(true.shape)\n",
    "#             print(true)\n",
    "            true = true.view(-1)\n",
    "            \n",
    "            j_loss = loss_func(preds, true)\n",
    "            j_loss.backward()\n",
    "#             print(j_loss)\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += j_loss.item()\n",
    "#             break\n",
    "        \n",
    "    return epoch_loss/len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_one_epoch(model, iterator, loss_func):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for batch in iterator:\n",
    "            text = batch.text\n",
    "#             print('Text shape: ', text.shape)\n",
    "\n",
    "            preds = model(batch.text)\n",
    "#             print(preds.shape)\n",
    "            preds = preds.view(-1)\n",
    "            true = batch.selection\n",
    "            true = true.view(-1)\n",
    "\n",
    "            j_loss = loss_func(preds, true)\n",
    "            \n",
    "            epoch_loss += j_loss.item()\n",
    "\n",
    "    return epoch_loss/len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 3s\n",
      "Train Loss: 1.055\n",
      "Val Loss: 1.051\n",
      "Epoch: 02 | Epoch Time: 0m 3s\n",
      "Train Loss: 1.037\n",
      "Val Loss: 1.036\n",
      "Epoch: 03 | Epoch Time: 0m 3s\n",
      "Train Loss: 1.028\n",
      "Val Loss: 1.031\n",
      "Epoch: 04 | Epoch Time: 0m 3s\n",
      "Train Loss: 1.023\n",
      "Val Loss: 1.027\n",
      "Epoch: 05 | Epoch Time: 0m 3s\n",
      "Train Loss: 1.019\n",
      "Val Loss: 1.024\n",
      "Epoch: 06 | Epoch Time: 0m 3s\n",
      "Train Loss: 1.016\n",
      "Val Loss: 1.020\n",
      "Epoch: 07 | Epoch Time: 0m 3s\n",
      "Train Loss: 1.012\n",
      "Val Loss: 1.018\n",
      "Epoch: 08 | Epoch Time: 0m 3s\n",
      "Train Loss: 1.010\n",
      "Val Loss: 1.015\n",
      "Epoch: 09 | Epoch Time: 0m 3s\n",
      "Train Loss: 1.008\n",
      "Val Loss: 1.013\n",
      "Epoch: 10 | Epoch Time: 0m 3s\n",
      "Train Loss: 1.006\n",
      "Val Loss: 1.011\n",
      "Epoch: 11 | Epoch Time: 0m 3s\n",
      "Train Loss: 1.004\n",
      "Val Loss: 1.008\n",
      "Epoch: 12 | Epoch Time: 0m 3s\n",
      "Train Loss: 1.002\n",
      "Val Loss: 1.006\n",
      "Epoch: 13 | Epoch Time: 0m 3s\n",
      "Train Loss: 1.000\n",
      "Val Loss: 1.004\n",
      "Epoch: 14 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.998\n",
      "Val Loss: 1.003\n",
      "Epoch: 15 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.997\n",
      "Val Loss: 1.001\n",
      "Epoch: 16 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.995\n",
      "Val Loss: 0.999\n",
      "Epoch: 17 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.993\n",
      "Val Loss: 0.998\n",
      "Epoch: 18 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.992\n",
      "Val Loss: 0.996\n",
      "Epoch: 19 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.989\n",
      "Val Loss: 0.994\n",
      "Epoch: 20 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.988\n",
      "Val Loss: 0.992\n",
      "Epoch: 21 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.986\n",
      "Val Loss: 0.992\n",
      "Epoch: 22 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.983\n",
      "Val Loss: 0.988\n",
      "Epoch: 23 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.981\n",
      "Val Loss: 0.987\n",
      "Epoch: 24 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.978\n",
      "Val Loss: 0.984\n",
      "Epoch: 25 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.975\n",
      "Val Loss: 0.983\n",
      "Epoch: 26 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.971\n",
      "Val Loss: 0.979\n",
      "Epoch: 27 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.968\n",
      "Val Loss: 0.978\n",
      "Epoch: 28 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.965\n",
      "Val Loss: 0.974\n",
      "Epoch: 29 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.961\n",
      "Val Loss: 0.973\n",
      "Epoch: 30 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.958\n",
      "Val Loss: 0.969\n",
      "Epoch: 31 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.953\n",
      "Val Loss: 0.967\n",
      "Epoch: 32 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.952\n",
      "Val Loss: 0.964\n",
      "Epoch: 33 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.947\n",
      "Val Loss: 0.961\n",
      "Epoch: 34 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.943\n",
      "Val Loss: 0.959\n",
      "Epoch: 35 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.940\n",
      "Val Loss: 0.957\n",
      "Epoch: 36 | Epoch Time: 0m 2s\n",
      "Train Loss: 0.939\n",
      "Val Loss: 0.955\n",
      "Epoch: 37 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.935\n",
      "Val Loss: 0.954\n",
      "Epoch: 38 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.933\n",
      "Val Loss: 0.953\n",
      "Epoch: 39 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.929\n",
      "Val Loss: 0.952\n",
      "Epoch: 40 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.926\n",
      "Val Loss: 0.951\n",
      "Epoch: 41 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.925\n",
      "Val Loss: 0.952\n",
      "Epoch: 42 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.922\n",
      "Val Loss: 0.951\n",
      "Epoch: 43 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.919\n",
      "Val Loss: 0.953\n",
      "Epoch: 44 | Epoch Time: 0m 2s\n",
      "Train Loss: 0.917\n",
      "Val Loss: 0.955\n",
      "Epoch: 45 | Epoch Time: 0m 2s\n",
      "Train Loss: 0.914\n",
      "Val Loss: 0.951\n",
      "Epoch: 46 | Epoch Time: 0m 2s\n",
      "Train Loss: 0.912\n",
      "Val Loss: 0.961\n",
      "Epoch: 47 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.913\n",
      "Val Loss: 0.948\n",
      "Epoch: 48 | Epoch Time: 0m 2s\n",
      "Train Loss: 0.908\n",
      "Val Loss: 0.956\n",
      "Epoch: 49 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.903\n",
      "Val Loss: 0.949\n",
      "Epoch: 50 | Epoch Time: 0m 2s\n",
      "Train Loss: 0.904\n",
      "Val Loss: 0.971\n",
      "Epoch: 51 | Epoch Time: 0m 2s\n",
      "Train Loss: 0.906\n",
      "Val Loss: 0.947\n",
      "Epoch: 52 | Epoch Time: 0m 2s\n",
      "Train Loss: 0.898\n",
      "Val Loss: 0.962\n",
      "Epoch: 53 | Epoch Time: 0m 2s\n",
      "Train Loss: 0.894\n",
      "Val Loss: 0.948\n",
      "Epoch: 54 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.894\n",
      "Val Loss: 0.974\n",
      "Epoch: 55 | Epoch Time: 0m 2s\n",
      "Train Loss: 0.892\n",
      "Val Loss: 0.947\n",
      "Epoch: 56 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.892\n",
      "Val Loss: 0.958\n",
      "Epoch: 57 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.882\n",
      "Val Loss: 0.955\n",
      "Epoch: 58 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.882\n",
      "Val Loss: 0.960\n",
      "Epoch: 59 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.879\n",
      "Val Loss: 0.959\n",
      "Epoch: 60 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.877\n",
      "Val Loss: 0.959\n",
      "Epoch: 61 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.874\n",
      "Val Loss: 0.954\n",
      "Epoch: 62 | Epoch Time: 0m 2s\n",
      "Train Loss: 0.877\n",
      "Val Loss: 0.959\n",
      "Epoch: 63 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.890\n",
      "Val Loss: 0.945\n",
      "Epoch: 64 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.883\n",
      "Val Loss: 0.963\n",
      "Epoch: 65 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.885\n",
      "Val Loss: 0.949\n",
      "Epoch: 66 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.885\n",
      "Val Loss: 0.958\n",
      "Epoch: 67 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.864\n",
      "Val Loss: 0.971\n",
      "Epoch: 68 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.866\n",
      "Val Loss: 0.963\n",
      "Epoch: 69 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.864\n",
      "Val Loss: 0.961\n",
      "Epoch: 70 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.867\n",
      "Val Loss: 0.945\n",
      "Epoch: 71 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.860\n",
      "Val Loss: 0.974\n",
      "Epoch: 72 | Epoch Time: 0m 2s\n",
      "Train Loss: 0.856\n",
      "Val Loss: 0.950\n",
      "Epoch: 73 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.851\n",
      "Val Loss: 0.976\n",
      "Epoch: 74 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.850\n",
      "Val Loss: 0.969\n",
      "Epoch: 75 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.851\n",
      "Val Loss: 0.982\n",
      "Epoch: 76 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.849\n",
      "Val Loss: 0.964\n",
      "Epoch: 77 | Epoch Time: 0m 2s\n",
      "Train Loss: 0.845\n",
      "Val Loss: 0.979\n",
      "Epoch: 78 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.842\n",
      "Val Loss: 0.967\n",
      "Epoch: 79 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.842\n",
      "Val Loss: 0.981\n",
      "Epoch: 80 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.840\n",
      "Val Loss: 0.955\n",
      "Epoch: 81 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.840\n",
      "Val Loss: 0.976\n",
      "Epoch: 82 | Epoch Time: 0m 2s\n",
      "Train Loss: 0.839\n",
      "Val Loss: 0.982\n",
      "Epoch: 83 | Epoch Time: 0m 2s\n",
      "Train Loss: 0.833\n",
      "Val Loss: 0.979\n",
      "Epoch: 84 | Epoch Time: 0m 2s\n",
      "Train Loss: 0.837\n",
      "Val Loss: 0.975\n",
      "Epoch: 85 | Epoch Time: 0m 2s\n",
      "Train Loss: 0.829\n",
      "Val Loss: 0.983\n",
      "Epoch: 86 | Epoch Time: 0m 2s\n",
      "Train Loss: 0.828\n",
      "Val Loss: 0.962\n",
      "Epoch: 87 | Epoch Time: 0m 2s\n",
      "Train Loss: 0.826\n",
      "Val Loss: 0.995\n",
      "Epoch: 88 | Epoch Time: 0m 2s\n",
      "Train Loss: 0.824\n",
      "Val Loss: 0.998\n",
      "Epoch: 89 | Epoch Time: 0m 2s\n",
      "Train Loss: 0.827\n",
      "Val Loss: 0.991\n",
      "Epoch: 90 | Epoch Time: 0m 2s\n",
      "Train Loss: 0.823\n",
      "Val Loss: 0.960\n",
      "Epoch: 91 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.822\n",
      "Val Loss: 0.996\n",
      "Epoch: 92 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.817\n",
      "Val Loss: 0.961\n",
      "Epoch: 93 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.816\n",
      "Val Loss: 0.998\n",
      "Epoch: 94 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.811\n",
      "Val Loss: 1.000\n",
      "Epoch: 95 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.820\n",
      "Val Loss: 0.978\n",
      "Epoch: 96 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.820\n",
      "Val Loss: 1.027\n",
      "Epoch: 97 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.836\n",
      "Val Loss: 1.004\n",
      "Epoch: 98 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.819\n",
      "Val Loss: 1.004\n",
      "Epoch: 99 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.808\n",
      "Val Loss: 0.979\n",
      "Epoch: 100 | Epoch Time: 0m 3s\n",
      "Train Loss: 0.800\n",
      "Val Loss: 0.994\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train_one_epoch(model, train_iterator, lovasz_hinge_flat, optimizer)\n",
    "    val_loss = val_one_epoch(model, valid_iterator, lovasz_hinge_flat)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_time_min, epoch_time_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_valid_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_time_min}m {epoch_time_secs}s')\n",
    "    print('Train Loss: {:.3f}'.format(train_loss))\n",
    "    print('Val Loss: {:.3f}'.format(val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = torch.randn(100,1000)\n",
    "# y = torch.randn(1000,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x.to(device); y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z = torch.matmul(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = torch.randn((32,18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x.nonzero().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = nn.CrossEntropyLoss()\n",
    "# input_ = torch.randn(3, 5, requires_grad=True)\n",
    "# target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "# print(input_); print(target)\n",
    "# output = loss(input_, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def my_loss(true, pred):\n",
    "#     # this is the new criterion\n",
    "    \n",
    "#     # expected true to be of shape (batch_size, None) -- but only 0, 1\n",
    "#     # expecting pred to be of shape (batch_size, None) -- but float values\n",
    "    \n",
    "#     true_start, true_end = true\n",
    "#     pred_start, pred_end = pred\n",
    "    \n",
    "#     pred_start_idx = (pred_start==1).nonzero()\n",
    "#     pred_end_idx = (pred_end==1).nonzero()\n",
    "    \n",
    "#     if pred_start_idx > pred_end_idx: return 100\n",
    "    \n",
    "#     true_start_idx = (true_start==1).nonzero()\n",
    "#     true_end_idx = (true_end==1).nonzero()\n",
    "    \n",
    "#     I = torch.min(true_end_idx, pred_end_idx) - torch.max(true_start_idx, pred_start_idx)\n",
    "#     if I < 0: return 1\n",
    "#     P = pred_end_idx - pred_start_idx\n",
    "#     T = true_end_idx - true_start_idx\n",
    "    \n",
    "#     smooth = 1e-6\n",
    "    \n",
    "#     loss = 1 - ((I + smooth) / (P + T - I + smooth))\n",
    "#     return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch in valid_iterator:\n",
    "#     text = batch.text\n",
    "#     print(text)\n",
    "#     pred = model(text)\n",
    "#     pred = torch.transpose\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.autograd import Variable\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# def lovasz_grad(gt_sorted):\n",
    "#     \"\"\"\n",
    "#     Computes gradient of the Lovasz extension w.r.t sorted errors\n",
    "#     See Alg. 1 in paper\n",
    "#     \"\"\"\n",
    "#     p = len(gt_sorted)\n",
    "#     gts = gt_sorted.sum()\n",
    "#     intersection = gts - gt_sorted.float().cumsum(0)\n",
    "#     union = gts + (1 - gt_sorted).float().cumsum(0)\n",
    "#     jaccard = 1. - intersection / union\n",
    "#     if p > 1: # cover 1-pixel case\n",
    "#         jaccard[1:p] = jaccard[1:p] - jaccard[0:-1]\n",
    "#     return jaccard\n",
    "\n",
    "# def lovasz_hinge_flat(logits, labels):\n",
    "#     \"\"\"\n",
    "#     Binary Lovasz hinge loss\n",
    "#       logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
    "#       labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
    "#       ignore: label to ignore\n",
    "#     \"\"\"\n",
    "#     if len(labels) == 0:\n",
    "#         # only void pixels, the gradients should be 0\n",
    "#         return logits.sum() * 0.\n",
    "#     signs = 2. * labels.float() - 1.\n",
    "#     errors = (1. - logits * Variable(signs))\n",
    "#     errors_sorted, perm = torch.sort(errors, dim=0, descending=True)\n",
    "#     perm = perm.data\n",
    "#     gt_sorted = labels[perm]\n",
    "#     grad = lovasz_grad(gt_sorted)\n",
    "#     loss = torch.dot(F.relu(errors_sorted), Variable(grad))\n",
    "#     return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x1 = torch.FloatTensor(2,3)\n",
    "# a = [[1,0,1],[0,1,1]]\n",
    "# a = np.array([np.array(aa,dtype=np.float32) for aa in a])\n",
    "# x2 = torch.tensor(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x1 = x1.view(-1)\n",
    "# x2 = x2.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lovasz_hinge_flat(x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf_3]",
   "language": "python",
   "name": "conda-env-tf_3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
